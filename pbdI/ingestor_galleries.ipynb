{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff9387e-51b2-4159-b525-1baa7a068415",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import fastparquet\n",
    "import pandas as pd\n",
    "from elasticsearch import helpers\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f07cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_path_separator = os.path.sep\n",
    "index_name = 'galleries'\n",
    "base_path = os.path.abspath('/opt/data/mates_pbd')\n",
    "process_folder = \"sahibinden_galleries\"\n",
    "template_name = 'galleries-template'\n",
    "template_pattern = \"galleries-*\"\n",
    "index_mapping = {\n",
    "    \"@timestamp\": { \"type\": \"date\" },\n",
    "    \"folder_index\": { \"type\": \"keyword\" },\n",
    "    \"external_id\": { \"type\": \"keyword\" },\n",
    "    \"make\": { \"type\": \"keyword\" },\n",
    "    \"model\": { \"type\": \"keyword\" },\n",
    "    \"trimlevel\": { \"type\": \"keyword\" },\n",
    "    \"car_year\": { \"type\": \"keyword\" },\n",
    "    \"km\": { \"type\": \"keyword\" },\n",
    "    \"color\": { \"type\": \"keyword\" },\n",
    "    \"price\": { \"type\": \"keyword\" },\n",
    "    \"url\": { \"type\": \"keyword\" },\n",
    "    \"car_name\": { \"type\": \"keyword\" },\n",
    "    \"dealer_name\": { \"type\": \"keyword\" },\n",
    "    \"seller_gallery_url\": { \"type\": \"keyword\" },\n",
    "    \"contact_phone\": { \"type\": \"keyword\" }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a94618",
   "metadata": {},
   "source": [
    "### Conexion Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d02db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(hosts=\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ccfadc",
   "metadata": {},
   "source": [
    "### Configuración Indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f898ca2d-6b43-4702-9159-7b429b14e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index\n",
    "index_config = {\n",
    "    \"settings\": {\n",
    "        \"index\": {\n",
    "            \"refresh_interval\": \"5s\"\n",
    "        },\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0,\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": index_mapping\n",
    "    }\n",
    "}\n",
    "\n",
    "# BORRAR INDICE!!!\n",
    "# if es.indices.exists(index=index_name):\n",
    "#     es.indices.delete(index=index_name)\n",
    "\n",
    "# Crear el índice\n",
    "if not es.indices.exists(index=index_name):\n",
    "    es.indices.create(index=index_name, body=index_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcc50f1",
   "metadata": {},
   "source": [
    "### Proceso de carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead5ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ef1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertar los datos mediante una funcion generadora (para no cargar todo en memoria)\n",
    "def generator(df, folder_name):\n",
    "    for index, row in df.iterrows():\n",
    "        yield {\n",
    "            \"_index\": index_name,\n",
    "            \"_source\": row.to_dict()\n",
    "        }\n",
    "\n",
    "\n",
    "# Recorrer los archivos recursivamente\n",
    "for filename in glob.iglob(os.path.join(base_path, process_folder, '**/*.parquet'), recursive=True):\n",
    "\n",
    "\n",
    "    try:\n",
    "        #\n",
    "        parquet_folder = os.path.dirname(filename).split(system_path_separator)[-1]\n",
    "        parquet_date = os.path.dirname(filename).split(system_path_separator)[-2]\n",
    "\n",
    "        # Solo cargar nuevos\n",
    "        # if int(parquet_date) < 20230300:\n",
    "        #     continue\n",
    "\n",
    "\n",
    "        # Comprobar si ya se ha cargado el fichero\n",
    "        query = {\n",
    "            \"query\": {\n",
    "                \"match\": {\n",
    "                    \"folder_index\": {\n",
    "                        \"query\": parquet_date+\"_\"+parquet_folder, # 20220211_46c09720-bee9-4da1-a9d2-8b062b5d151c\n",
    "                        \"auto_generate_synonyms_phrase_query\": False,\n",
    "                        \"fuzziness\": 0\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "        res = es.search(index=index_name, body=query,)\n",
    "        if res['hits']['total']['value'] > 0:\n",
    "            # print(f'Already loaded {filename}')\n",
    "            found = False\n",
    "            for hit in res['hits']['hits']:\n",
    "                if hit['_source']['folder_index'] == parquet_date+\"_\"+parquet_folder:\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                print(f'Already loaded {filename}')\n",
    "                continue\n",
    "\n",
    "        # Cargar el fichero parquet\n",
    "        pf = fastparquet.ParquetFile(filename)\n",
    "        df = pf.to_pandas()\n",
    "        # Parse scrapping_datetime a datetime (2023-02-02 19:44:16)\n",
    "        df['scrapping_datetime'] = pd.to_datetime(df['scrapping_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "        # Renombrear scrapping_datetime a @timestamp\n",
    "        df = df.rename(columns={'scrapping_datetime': '@timestamp'})\n",
    "\n",
    "        # Eliminar columnas que no se van a usar\n",
    "        if 'crawling_job_id' in df.columns:\n",
    "            df = df.drop(columns=['crawling_job_id'])\n",
    "        if 'crawling_job_datetime' in df.columns:\n",
    "            df = df.drop(columns=['crawling_job_datetime'])\n",
    "        if 'crawling_job_date' in df.columns:\n",
    "            df = df.drop(columns=['crawling_job_date'])\n",
    "\n",
    "        # Identificador del fichero\n",
    "        df[\"folder_index\"] = parquet_date+\"_\"+parquet_folder\n",
    "\n",
    "        # Insertar el archivo en bulk\n",
    "        helpers.bulk(es, generator(df, parquet_folder))\n",
    "        print(f'Loaded {filename} With {len(df)} rows')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Error')\n",
    "        failed_files.append(filename)\n",
    "        # break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
